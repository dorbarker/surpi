#!/usr/bin/env python3

import os
import argparse
import subprocess
import tempfile
from functools import partial
from pathlib import Path
from multiprocessing import cpu_count
from utilities import logtime, annotated_to_fastq, fastq_to_fasta
from Bio import SeqIO
from taxonomy_lookup import taxonomy_lookup, table_generator

def arguments():

    parser = argparse.ArgumentParser()

    parser.add_argument('--sample', type=Path,
                        help='Input fastq file')

    parser.add_argument('--workdir', type=Path,
                        help='Work directory for SURPI')

    parser.add_argument_group('--cores', type=int,
                              default=cpu_count(),
                              help='CPU cores to use [all]')

    return parser.parse_args()

@logtime('Separate matched and unmatched sequences from SAM file')
def separate_sam_lines(sam_file):
    '''Separates SAM-formatted file.

    Lines where the third column is '*' are appended to matched,
    and appended to unmatched otherwise.
    '''

    matched, unmatched = [], []

    with open(sam_file, 'r') as sam:

        for line in sam:
            if not line.startswith('@'):

                split_line = line.split('\t')

                if split_line[2] == '*':
                    matched.append(line)
                else:
                    unmatched.append(line)

    return matched, unmatched

def write_sam(lines, outpath):
    '''Writes SAM lines generated by separate_sam_lines()'''

    with open(outpath, 'w') as out:

        out.write('\n'.join(lines))

@logtime('SNAP unmatched sequences')
def snap_unmatched(basef, workdir, db_dir, unmatched, cache_reset,
                   edit_distance, cores):

    # edit_distance == d_NT_alignment
    snap_sam = basef.with_suffix('.NT.snap.sam')

    if not snap_sam.exists():

        snap_nt_cmd = ('snap_nt.sh', unmatched, db_dir, cores, cache_reset,
                       edit_distance, 'snap-aligner')

        subprocess.check_call(map(str, snap_nt_cmd))

    os.rename(str(workdir / unmatched), str(workdir / snap_sam))

def separate_ranked_taxonomy(ranks, annotations, result_dir):
    '''Recursively searches through `ranks` and writes taxonomy results
    to files name after the given rank.

    Ranks must be ordered from broad to narrow,
    e.g. ['Eurkaryota', 'Chordata', 'Mammalia', 'Primates']
    '''

    def condition(line, to_find, to_exclude):
        return to_find in line and to_exclude not in line

    def tax_search_recursor(rank_list):

        to_find, to_exclude = rank_list[-2:]

        test = partial(condition, to_find=to_find, to_exclude=to_exclude)

        result_file = (result_dir / to_find).with_suffix('.annotated')

        sub_annot = (line for line in annotations if test(line))

        result_file.write_text('\n'.join(sub_annot))

        if len(rank_list) > 2:

            rank_list = rank_list[:-1]

            tax_search_recursor(rank_list)

        else:

            return result_file

    ranks_ = ranks.append('loremipsumdolorsitamet')  # ensure never found

    result_file = tax_search_recursor(ranks_)

    return result_file

def ribo_snap(name, mode, cores, ribo_dir):

    ribo_snap = ('ribo_snap_bac_euk.sh', name, mode, cores, ribo_dir)

    subprocess.check_call(map(str, ribo_snap))

def extract_headers(basef, workdir, cores):

    cmd = (
        'extractHeaderFromFastq_ncores.sh', cores,
        workdir / basef.with_suffix('.cutadapt.fastq'),
        workdir / basef.with_suffix('.NT.snap.matched.sam'),
        workdir / basef.with_suffix('.NT.snap.matched.fulllength.fastq'),
        workdir / basef.with_suffix('.NT.snap.unmatched.sam'),
        workdir / basef.with_suffix('.NT.snap.unmatched.fulllength.fastq')
        )

    subprocess.check_call(map(str, cmd))

    return cmd[-1]

def lookup_taxonomy(basef, annotated, workdir, tax_db_dir, ribo_dir, cores):

    full_length_fastq = basef.with_suffix('.NT.snap.matched.fulllength.fastq')
    full_length_sam = full_length_fastq.with_suffix('.sam')

    # sort sam
    with open(workdir / basef.with_suffix('.NT.snap.matched.sam')) as sam:

        lines = sam.readlines()
        sorted_lines = sorted(lines, key=lambda x: x[0])

    # may need to double-check sequence sorting here
    with open(workdir / full_length_fastq) as fastq:
        seq_quals = []
        for rec in SeqIO.parse(fastq, 'fastq'):
            fastq_lines = rec.splitlines()
            seq_quals.append([fastq_lines[1], fastq_lines[3]])

    # paste
    with open(full_length_sam, 'w') as out_sam:

        for line, qual  in zip(sorted_lines, seq_quals):

            to_write = line[:9] + qual + line[11:] + ['\n']

            out_sam.write('\t'.join(to_write))

    taxonomy_lookup(infile=full_length_sam,
                    outfile=annotated,
                    db_dir=tax_db_dir,
                    file_type='sam',
                    seq_type='nucl')

    # TODO: check final annotation sort -k 13.7n

    viruses = separate_ranked_taxonomy(ranks=('Viruses',),
                                       annotations=annotated,
                                       result_dir=workdir)

    bacteria = separate_ranked_taxonomy(ranks=('Bacteria',),
                                        annotations=annotated,
                                        result_dir=workdir)

    euks = separate_ranked_taxonomy(ranks=('Eukaryota', 'Chordata',
                                           'Mammalia', 'Primates'),
                                    annotations=annotated,
                                    result_dir=workdir)

    ribo_snap(bacteria, 'BAC', cores, ribo_dir)
    ribo_snap(euks, 'EUK', cores, ribo_dir)

    return viruses, bacteria, euks

def extract_to_fast(fastq, fasta, output):

    def subseq(infile, parent, outfile):

        header_file = infile.with_suffix('.headers')
        headers = [line[1:] for line in infile.read_text().splitlines()
                   if line.startswith('>')]

        header_file.write_text('\n'.join(headers))

        cmd = ('seqtk', 'subseq', parent, header_file)

        output = subprocess.check_output(cmd)

        Path(output).write_text(output)

        header_file.unlink()

    def sequniq(infile, outfile):
        '''Filters redundant sequence from `infile`'''

        cmd = ('gt', 'sequniq', '-seqit', '-force', '-o', outfile, infile)

        subprocess.check_call(map(str, cmd))

    def crop_reads(infile, outfile):
        '''Runs crop_reads.csh on `infile` with some default settings'''

        cmd = ('crop_reads.csh', infile, 25, 50)

        cropped = subprocess.check_output(map(str, cmd),
                                          universal_newlines=True)

        outfile.write_text(cropped)

    def sort_fasta_by_length(unsorted_fasta, sorted_fasta):
        '''Sorts a FASTA file by descending sequence length and writes it to
        a new FASTA file
        '''

        with unsorted_fasta.open('r') as fasta, sorted_fasta.open('w') as out:

            records = SeqIO.parse(fasta, 'fasta')

            sorted_records = sorted(records,
                                    key=lambda x: len(x.seq),
                                    reverse=True)

            SeqIO.write(sorted_records, out, 'fasta')

    fastq_to_fasta(fastq, fasta)

    with tempfile.TemporaryDirectory() as temp_dir:

        temp_dir_path = Path(temp_dir)

        sorted_fasta = (temp_dir_path / fasta).with_suffix('.sorted')

        cropped = sorted_fasta.with_suffix('.cropped')

        uniq = cropped.with_suffix('.uniq')

        sort_fasta_by_length(fasta, sorted_fasta)

        crop_reads(sorted_fasta, cropped)

        sequniq(cropped, uniq)

        subseq(uniq, fasta, output)

def snap(sample, workdir, snap_db_dir, tax_db_dir, ribo_dir, cores,
         edit_distance, cache_reset, comprehensive):

    basef = Path(sample.stem)
    annotated = workdir / basef.with_suffix('.annotated')

    snap_unmatched(basef, workdir, snap_db_dir, unmatched, cache_reset,
                   edit_distance, cores)

    snap_sam = workdir / basef.with_suffix('.NT.snap.sam')

    matched, unmatched = separate_sam_lines(snap_sam)

    write_sam(matched, workdir / basef.with_suffix('.NT.snap.matched.sam'))
    write_sam(unmatched, workdir / basef.with_suffix('.NT.snap.unmatched.sam'))

    if not annotated.exists():

        fulllength_fastq = extract_headers(basef, workdir, cores)
        viruses, bacteria, euks = lookup_taxonomy(basef, workdir, tax_db_dir,
                                                  ribo_dir, cores)

    table_generator(viruses, 'SNAP', 'Y', 'Y', 'Y', 'Y')

    if comprehensive:

        viruses.with_suffix('.fastq').write_text(annotated_to_fastq(viruses))

        # output of this given to denovo assembly and RAPSearch
        extract_to_fast(fulllength_fastq,
                        fulllength_fastq.with_suffix('.fasta'),
                        fulllength_fastq.with_suffix('.uniq.f1.fasta'))

def main():

    args = arguments()

    #snap(args.sample, args.workdir, args.db_dir, args.cores)

if __name__ == '__main__':
    main()
