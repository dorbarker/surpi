#!/usr/bin/env python3

import os
import argparse
from pathlib import Path
from utilities import run_shell, logtime
from multiprocessing import cpu_count
from Bio import SeqIO

def arguments():

    parser = argparse.ArgumentParser()

    parser.add_argument('--sample', type=Path,
                        help='Input fastq file')

    parser.add_argument('--workdir', type=Path,
                        help='Work directory for SURPI')

    parser.add_argument_group('--cores', type=int,
                              default=cpu_count(),
                              help='CPU cores to use [all]')

    return parser.parse_args()

@logtime('Separate matched and unmatched sequences from SAM file')
def separate_sam_lines(sam_file):
    '''Separates SAM-formatted file.

    Lines where the third column is '*' are appended to matched,
    and appended to unmatched otherwise.
    '''

    matched, unmatched = [], []

    with open(sam_file, 'r') as f:

        for line in f:
            if not line.startswith('@'):

                split_line = line.split('\t')

                if split_line[2] == '*':
                    matched.append(line)
                else:
                    unmatched.append(line)

    return matched, unmatched

def write_sam(lines, outpath):
    '''Writes SAM lines generated by separate_sam_lines()'''

    with open(outpath, 'w') as f:

        f.write('\n'.join(lines))

@logtime('SNAP unmatched sequences')
def snap_unmatched(basef, workdir, db_dir, unmatched, cache_reset,
                   d_NT_alignment, snap_path, cores):

    snap_sam = basef.with_suffix('.NT.snap.sam')

    if not snap_sam.exists():

        snap_nt_cmd = ('snap_nt.sh', unmatched, db_dir, cores, cache_reset,
                       d_NT_alignment, snap_path)

        snap_nt_cmd = ' '.join(map(str, snap_nt_cmd))

        run_shell(snap_nt_cmd)

    os.rename(str(workdir / unmatched), str(workdir / snap_sam))

def lookup_taxonomy(basef, workdir):

    annotated = basef.with_suffix('.NT.snap.matched.all.annotated')
    full_length_fastq = basef.with_suffix('.NT.snap.matched.fulllength.fastq')
    full_length_sam = full_length_fastq.with_suffix('.sam')

    if not annotated.exists():
        extract_headers = (
            'extractHeaderFromFastq_ncores.sh', cores,
            workdir / basef.with_suffix('.cutadapt.fastq'),
            workdir / basef.with_suffix('.NT.snap.matched.sam'),
            workdir / basef.with_suffix('.NT.snap.matched.fulllength.fastq'),
            workdir / basef.with_suffix('.NT.snap.unmatched.sam'),
            workdir / basef.with_suffix('.NT.snap.unmatched.fulllength.fastq')
            )

        run_shell(' '.join(map(str, extract_headers)))

        # sort sam

        with open(workdir / basef.with_suffix('.NT.snap.matched.sam') as s:

            lines = s.readlines()
            sorted_lines = sorted(lines, key = lambda x: x[0])

        # may need to double-check sequence sorting here
        with open(workdir / full_length_fastq) as fq:
            seq_quals = []
            for rec in SeqIO.parse(fq, 'fastq'):
                fastq_lines = rec.splitlines()
                seq_quals.append( [fastq_lines[1], fastq_lines[3]] )

        with open(full_length_sam, 'w') as out_sam:

            for a, b  in zip(sorted_lines, seq_quals):

                to_write = a[:9] + b + a[11:] + ['\n']

                out_sam.write( '\t'.join(to_write) )

def snap(sample, workdir, cores):

    basef = Path(sample.with_suffix('').name)

    db_dir = comp_db_dir if comprehensive else fast_db_dir
    snap_sam = workdir / basef.with_suffix('.NT.snap.sam')

    snap_unmatched(basef, workdir, db_dir, unmatched, cache_reset,
                   d_NT_alignment, snap_path, cores)

    matched, unmatched = separate_sam_lines(snap_sam)

    write_sam(matched, workdir / basef.with_suffix('.NT.snap.matched.sam'))
    write_sam(unmatched, workdir / basef.with_suffix('.NT.snap.unmatched.sam'))


def main():

    args = arguments()

    snap(args.sample, args.workdir)

if __name__ == '__main__':
    main()
